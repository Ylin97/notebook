# 多线程编程小结

## 基础知识

- **C++11** 开始引入标准线程库 `<thread>`，统一封装了底层的操作系统线程（如 POSIX pthread、Windows thread），让多线程编程更简洁。

- 线程通过 `std::thread` 创建，使用时需关注数据竞争和同步，可使用 `std::mutex`、`std::lock_guard`、`std::unique_lock`、`std::condition_variable` 等工具。

  ```cpp
  void Work() { /* ... */ }
  std::thread t(Work);  // 启动线程
  t.join();             // 等待线程结束
  ```

- **线程生命周期**
   线程启动后必须通过 `join()` 等待结束，或通过 `detach()` 让其独立运行。否则在对象析构时会导致程序终止。`join()` 的语义和作用见【[此处](#1. join 的语义、作用与历史)】。

------

## 传递引用问题

- 多线程函数传参时，如果要 **按引用传递**，必须使用 `std::ref` 包装，否则会进行按值复制甚至无法编译：

  ```cpp
  void Worker(int &var) { /* ... */ }
  
  int main() {
      int var = 0;
      std::thread t(Worker, std::ref(var)); // ✅ 按引用传递
      t.join();
  }
  ```

------

## joinable() 检查与 join

- 调用 `join()` 或 `detach()` 之前务必检查：

  ```cpp
  if (t.joinable()) t.join();
  ```

- `joinable()` 为 `false` 的几种情况：

  1. 线程对象默认构造；
  2. 已经调用过 `join()`；
  3. 已经调用过 `detach()`；
  4. 已经被移动赋值。

------

## 同步与互斥

### 互斥量（mutex）

- 使用 `std::mutex` 和 `std::lock_guard`/`std::unique_lock` 保护共享数据：

  ```cpp
  std::mutex m;
  int shared = 0;
  
  void Increment() {
      std::lock_guard<std::mutex> lk(m);
      ++shared;
  }
  ```

- `std::lock_guard` 和 `std::unique_lock` 都提供 RAII 自动解锁，避免忘记释放锁。两者的主要区别是 `std::unique_lock` 支持手动加解锁，而 `std::lock_guard` 不支持。具体对比见【[此处](#2. lock_guard 和 unique_lock 的区别)】

### 条件变量（condition_variable）

- 用于线程间等待/通知：

  ```cpp
  std::condition_variable cv;
  std::mutex m;
  bool ready = false;
  
  void Producer() {
      {
          std::lock_guard<std::mutex> lk(m);
          ready = true;
      }
      cv.notify_one();
  }
  
  void Consumer() {
      std::unique_lock<std::mutex> lk(m);
      cv.wait(lk, []{ return ready; });
      // 消费
  }
  ```

------

## detach() 与资源管理

- `detach()` 会让线程在后台独立运行，但此时无法再 `join()`，也无法确定其何时结束：

  ```cpp
  std::thread t(Work);
  t.detach();  // 主线程不再管理此线程
  ```

- 适用于短生命周期任务，但要避免访问已经销毁的资源。

------

## 原子操作

- `std::atomic<T>` 提供无锁的线程安全操作：

  ```cpp
  std::atomic<int> counter{0};
  void Increment() { counter.fetch_add(1); }
  ```

- 适用于简单计数或标志位，而不必使用互斥量。

------

## 线程局部存储

- 使用 `thread_local` 为每个线程维护独立副本：

  ```cpp
  thread_local int localVar = 0;
  ```

------

## 线程池与任务调度

- 为了避免频繁创建/销毁线程，常用**线程池**。线程池会维护一组工作线程，从任务队列中取出任务执行。
- 改进点：
  - 动态伸缩：根据任务负载增减线程数量；
  - 任务优先级：使用 `std::priority_queue`；
  - 异常处理：在工作线程内捕获异常，避免线程崩溃；
  - 监控：周期性输出线程池状态。

------

## 常见陷阱与最佳实践

- ❗ **忘记 join/detach**：导致程序异常终止。
- ❗ **数据竞争**：多个线程未同步访问共享数据。
- ❗ **死锁**：锁获取顺序不当或重复加锁。
- ✅ 使用 RAII（如 `lock_guard`）管理锁。
- ✅ 避免长时间持有锁，缩小临界区范围。
- ✅ 使用 `std::async`、`std::future` 简化异步任务。
- ✅ 对复杂场景使用现成库（如 TBB、Boost.Thread、Folly）。

------

### 🌟 **总结**

C++11 及之后的标准库提供了跨平台的线程与同步机制，使多线程编程更安全、更易用。掌握基本 API（`thread`、`mutex`、`condition_variable`、`atomic`）后，再结合线程池、任务优先级和动态伸缩等高级技术，就能构建高性能、可扩展的多线程程序。

------

## 附录

> ### 1. join 的语义、作用与历史
>
> #### ✨ **语义和作用**
>
> - `join()` 的意思是：**让当前线程等待（“加入”）另一个线程，直到那个线程运行结束**。
> - 调用 `t.join()` 的线程会 **阻塞**，直到线程 `t` 完成。此时两个线程的执行流在这一点 **汇合（join）**，形成同步点。
> - 调用后，`t` 与底层线程解绑，`t.joinable() == false`。
> - **用途**：
>   - 确保后台任务完成并释放资源。
>   - 在程序退出或继续依赖线程结果时，确保线程安全结束。
>
> #### 🕰 **历史与比喻**
>
> - **历史背景**：
>   - “join” 一词源自早期 Unix 和 POSIX 线程库（`pthread_join`），语义是“在这里汇合”。
> - **形象比喻**：
>   - 启动线程就像走出一条分叉的小路。
>   - 主线程执行到 `join()` 时，会在此等待那条分叉小路回到主路，类似**道路汇合（join paths）**。
>
> #### 🧩惯用写法
>
> ```cpp
> for (auto &worker : workers) {
>     if (worker.joinable()) {  // ✅ 检查是否可 join
>         worker.join();        // ✅ 等待线程完成并回收资源
>     }
> }
> ```
>
> ### 2. lock_guard 和 unique_lock 的区别
>
> #### 🔒 两者的共同点
>
> | 特性           | 说明                                                       |
> | -------------- | ---------------------------------------------------------- |
> | **RAII**       | 构造函数时加锁，析构函数时自动解锁。                       |
> | **作用域管理** | 当对象离开作用域（正常返回或异常抛出）时，锁会被自动释放。 |
> | **异常安全**   | 即使发生异常，析构函数仍会执行，防止死锁。                 |
>
> ------
>
> #### 🔧 两者的主要区别
>
> | 比较项               | `std::lock_guard`                      | `std::unique_lock`                                           |
> | -------------------- | -------------------------------------- | ------------------------------------------------------------ |
> | **是否支持手动解锁** | ❌ 不支持，锁定后必须等作用域结束才解锁 | ✅ 支持 `unlock()` 和 `lock()` 重新加锁                       |
> | **延迟加锁**         | ❌ 不支持，构造时就必须立即加锁         | ✅ 可以用 `std::defer_lock` 延迟加锁，或用 `try_to_lock` 尝试 |
> | **和条件变量配合**   | ❌ 不适合（无法在等待期间释放锁）       | ✅ 与 `std::condition_variable::wait` 等配合使用              |
> | **开销**             | 较小，接口简单                         | 略大一些（因为提供更多灵活性）                               |
>
> ------
>
> #### ✅ **示例：`lock_guard`（简单锁）**
>
> ```cpp
> std::mutex mtx;
> 
> void foo() {
>     std::lock_guard<std::mutex> lock(mtx); // 构造时加锁
>     // 临界区
> } // 作用域结束，自动解锁
> ```
>
> ------
>
> #### ✅ **示例：`unique_lock`（灵活锁）**
>
> ```cpp
> std::mutex mtx;
> 
> void bar() {
>     std::unique_lock<std::mutex> lock(mtx); // 构造时加锁
>     // 可以在这里提前解锁
>     lock.unlock();
> 
>     // 需要时重新加锁
>     lock.lock();
> } // 析构时如果还持有锁，会自动解锁
> ```
>
> ### 3. 支持动态伸缩的简易版线程池实现
>
> ```cpp
> #include <iostream>
> #include <thread>
> #include <mutex>
> #include <condition_variable>
> #include <queue>
> #include <vector>
> #include <functional>
> #include <chrono>
> #include <atomic>
> #include <algorithm>
> 
> struct Task {
>     int priority; // 优先级，数值越大优先级越高
>     std::function<void()> func;
> 
>     bool operator<(const Task &rhs) const {
>         return priority < rhs.priority; // 大顶堆
>     }
> };
> 
> class SmartThreadPool {
> public:
>     explicit SmartThreadPool(size_t min_threads = 2, size_t max_threads = 8,
>                              std::chrono::milliseconds idle_timeout = std::chrono::milliseconds(2000))
>         : min_threads_(min_threads), max_threads_(max_threads), idle_timeout_(idle_timeout),
>           active_threads_(0), completed_tasks_(0), alive_threads_(0), stop_(false) {
>         for (size_t i = 0; i < min_threads_; ++i) {
>             AddWorker();
>         }
>         monitor_ = std::thread([this] { MonitorLoop(); });
>     }
> 
>     ~SmartThreadPool() {
>         {
>             std::lock_guard<std::mutex> lock(mtx_);
>             stop_ = true;
>         }
>         cv_.notify_all();
> 
>         for (auto &worker : workers_) {
>             if (worker.joinable()) worker.join();
>         }
>         if (monitor_.joinable()) monitor_.join();
>     }
> 
>     void Enqueue(std::function<void()> task, int priority = 0) {
>         {
>             std::lock_guard<std::mutex> lock(mtx_);
>             tasks_.push(Task{priority, std::move(task)});
> 
>             if (active_threads_ >= alive_threads_ && workers_.size() < max_threads_) {
>                 AddWorker();
>             }
>         }
>         cv_.notify_one();
>     }
> 
> private:
>     std::vector<std::thread> workers_;
>     std::priority_queue<Task> tasks_;
>     std::mutex mtx_;
>     std::condition_variable cv_;
>     std::atomic<bool> stop_;
> 
>     size_t min_threads_;
>     size_t max_threads_;
>     std::chrono::milliseconds idle_timeout_;
> 
>     std::atomic<size_t> active_threads_;
>     std::atomic<size_t> completed_tasks_;
>     std::atomic<size_t> alive_threads_;
> 
>     std::thread monitor_;
> 
> private:
>     void AddWorker() {
>         // 或用传统方式
>         // workers_.emplace_back(&SmartThreadPool::WorkerLoop, this));
>         workers_.emplace_back([this] { WorkerLoop(); });
>     }
> 
>     void WorkerLoop() {
>         ++alive_threads_;
>         while (true) {
>             Task task;
>             { // 取任务
>                 std::unique_lock<std::mutex> lock(mtx_);
>                 if (!cv_.wait_for(lock, idle_timeout_, [this] { return stop_ || !tasks_.empty(); })) { // 线程空闲超时
>                     if (workers_.size() > min_threads_) {
>                         --alive_threads_;
>                         return;
>                     }
>                     continue;
>                 }
>                 if (stop_ && tasks_.empty()) {
>                     --alive_threads_;
>                     return;
>                 }
> 
>                 task = std::move(tasks_.top());
>                 tasks_.pop();
>             }
> 
>             ++active_threads_;
>             try {
>                 task.func();
>             } catch (const std::exception &e) {
>                 std::cerr << "[异常捕获] " << e.what() << '\n';
>             } catch (...) {
>                 std::cerr << "[异常捕获] " << "未知异常" << '\n';
>             }
>             --active_threads_;
>             ++completed_tasks_;
>         }
>     }
> 
>     void MonitorLoop() {
>         while (!stop_) {
>             std::this_thread::sleep_for(std::chrono::seconds(1)); // 暂停1秒，避免频繁锁
>             {
>                 std::lock_guard<std::mutex> lock(mtx_);
>                 CleanUpDeadThreads();
>                 std::cout << "[监控] 活动线程: " << active_threads_
>                           << " / 存活线程: " << alive_threads_
>                           << " / 容器线程: " << workers_.size()
>                           << " | 队列长度: " << tasks_.size()
>                           << " | 已完成任务: " << completed_tasks_ << "\n";
>             }
>         }
>     }
> 
>     void CleanUpDeadThreads() {
>         workers_.erase(std::remove_if(workers_.begin(), workers_.end(), [](const std::thread &t) { return !t.joinable(); }),
>                        workers_.end());
>     }
> };
> 
> int main() {
>     SmartThreadPool pool(2, 6, std::chrono::milliseconds(1500));
> 
>     pool.Enqueue([] {
>         std::cout << "高优先级任务\n";
>         std::this_thread::sleep_for(std::chrono::milliseconds(500)); }, 10);
> 
>     for (int i = 0; i < 10; ++i) {
>         pool.Enqueue([i] {
>             std::cout << "任务 " << i << "\n";
>             std::this_thread::sleep_for(std::chrono::milliseconds(300)); }, i % 5);
>     }
> 
>     std::this_thread::sleep_for(std::chrono::seconds(8));
>     std::cout << "主线程结束\n";
> }
> ```
>
> 
